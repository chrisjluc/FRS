{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>CNN-H1 3-26-2016</h1>\n",
    "\n",
    "<strong>Abstract</strong>\n",
    "Setting up the framework to train and test the MM-DFR. Implementing the CNN-H1 using NN2 described in the paper: http://arxiv.org/pdf/1509.00244v1.pdf\n",
    "\n",
    "<strong>Improvements</strong>\n",
    "<ul>\n",
    "<li>Take the people with the highest number of images for validation (top 900)</li>\n",
    "<li>Greyscale images - focus on the edges, features rather than colour</li>\n",
    "<li>Prevent overfitting by horizontally flipping images</li>\n",
    "<li>Normalize images to 230x230 (similar to the paper)</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import os\n",
    "import fnmatch\n",
    "import numpy as np\n",
    "\n",
    "from skimage import io\n",
    "from skimage.color import rgb2grey\n",
    "from skimage.transform import resize\n",
    "\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers.convolutional import Convolution2D, MaxPooling2D, ZeroPadding2D, AveragePooling2D\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.models import model_from_json\n",
    "\n",
    "np.random.seed(123456)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_path = '../data/lfw_cropped'\n",
    "\n",
    "img_rows, img_cols = 230, 230\n",
    "train_size_percent = .85\n",
    "validation_split = .15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Loading Files</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_face_to_file_path_dict():\n",
    "    face_to_file_paths_dict = {}\n",
    "    \n",
    "    for root, dirnames, filenames in os.walk(data_path):\n",
    "        for dirname in dirnames:\n",
    "            if dirname not in face_to_file_paths_dict:\n",
    "                face_to_file_paths_dict[dirname] = []\n",
    "            directory_path = os.path.join(data_path, dirname)\n",
    "            for filename in os.listdir(directory_path):\n",
    "                if filename.endswith(\".jpg\"):\n",
    "                    face_to_file_paths_dict[dirname].append(os.path.join(directory_path, filename))\n",
    "                            \n",
    "    return face_to_file_paths_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_face_to_file_paths_descending_list(face_to_file_paths_dict):\n",
    "    return sorted(face_to_file_paths_dict.items(), key=lambda x: len(x[1]), reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "face_to_file_paths_dict = get_face_to_file_path_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "face_to_file_paths_list = get_face_to_file_paths_descending_list(face_to_file_paths_dict)[:900]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Data Pre-Processing</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def image_read(f):\n",
    "    return resize(rgb2grey(io.imread(f)), (img_rows, img_cols))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def reflection(image):\n",
    "    return np.array([list(reversed(row)) for row in image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "images_by_class = [[image_read(f) for f in x[1]] for x in face_to_file_paths_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in range(len(images_by_class)):\n",
    "    images_by_class[i] += [reflection(image) for image in images_by_class[i]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X_train = np.array([image for images in images_by_class for image in images])\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "y_train = np.array([images[0] for images in enumerate(images_by_class) for image in images[1]])\n",
    "Y_train = np_utils.to_categorical(y_train, len(images_by_class))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Training and Validation</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def NN2(input_shape, nb_classes, nb_fc6):\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Layer 1\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu', input_shape=input_shape))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 2\n",
    "    model.add(Convolution2D(64, 3, 3, activation='relu'))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    # Layer 3\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(128, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    #Layer 4\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(MaxPooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    #Layer 5\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3, activation='relu'))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(Convolution2D(256, 3, 3))\n",
    "    model.add(ZeroPadding2D((1,1)))\n",
    "    model.add(AveragePooling2D((2,2), strides=(2,2)))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(0.4))\n",
    "    model.add(Dense(nb_fc6))\n",
    "    model.add(Dense(nb_classes, activation='softmax'))\n",
    "   \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape = (1, 230, 230)\n",
    "nb_classes = len(images_by_class)\n",
    "nb_fc6 = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = NN2(input_shape, nb_classes, nb_fc6)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd')\n",
    "model.fit(X_train, Y_train, batch_size=1, nb_epoch=10, \n",
    "        show_accuracy=True, verbose=1, shuffle=True, validation_split=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer=SGD(lr=0.001))\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, mode='min')\n",
    "model.fit(X_train, Y_train, batch_size=1, nb_epoch=50, early_stopping=early_stopping, \n",
    "        show_accuracy=True, verbose=1, shuffle=True, validation_split=.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "json_string = model.to_json()\n",
    "open('models/CNN-H1 .json', 'w').write(json_string)\n",
    "model.save_weights('models/CNN-H1.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
